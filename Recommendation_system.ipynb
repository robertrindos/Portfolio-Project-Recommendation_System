{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, util\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "#import dask.dataframe as dd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_csv_files():\n",
    "    critic_reviews = pd.read_csv(critic_reviews_url)\n",
    "    movies = pd.read_csv(movies_url)\n",
    "    return critic_reviews, movies\n",
    "#critic_reviews, movies = open_csv_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_orig_columns_na(movies, critic_reviews):\n",
    "    print(\"critic_reviews.csv NA ccount: \", critic_reviews.isna().sum())\n",
    "    print(\"critic_reviews.csv length: \", len(critic_reviews))\n",
    "    print(\" \")\n",
    "    print(\"movies.csv NA count: \", movies.isna().sum())\n",
    "    print(\"movies.csv length: \", len(movies))\n",
    "#print_orig_columns_na(movies, critic_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comma_to_space(text_df):\n",
    "    for col in text_df:\n",
    "        text_df[col].apply(lambda x: str(x).replace(',', ' '))\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text_df):\n",
    "    for col in text_df:\n",
    "        text_df[col].apply(lambda x: str(x).replace(' ', ''))\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_movie_dups(df,movie_titles):\n",
    "    df.drop_duplicates(movie_titles).reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies=drop_movie_dups(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_count_features(df, feature_list):\n",
    "    count_feature_list = ['genres', 'directors', 'authors', 'actors', 'production_company']\n",
    "    count_features = df[count_feature_list]\n",
    "    return count_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_features = define_count_features(movies)\n",
    "#count_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_count_features(count_features):\n",
    "    clean_features = count_features.fillna(' ', inplace=False)\n",
    "    for col in clean_features:\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace(' ', '', regex=True))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace(',', ' ', regex=True))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).lower())\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('[^\\w\\s]+','', regex=True))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('&', ' ', regex=True))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('.', '', regex=True))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('<', '', regex=True))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('>', '', regex=True))\n",
    "    return clean_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_features=clean_count_features(count_features)\n",
    "#clean_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_bow(clean_features):\n",
    "    count_features = ['genres', 'directors', 'authors', 'actors', 'production_company']\n",
    "    count_bow = clean_features[count_features].agg(' '.join, axis=1)\n",
    "    return count_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_bow = create_count_bow(clean_features)\n",
    "#count_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(bow):\n",
    "    token_array=[]\n",
    "    for text in bow:\n",
    "        tokens=word_tokenize(text)\n",
    "        token_array.append(tokens)\n",
    "    token_df = pd.DataFrame(token_array)\n",
    "    token_df.replace(to_replace=[None], value=' ', inplace=True)\n",
    "    return token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized=tokenize(count_bow)\n",
    "#tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorize(count_bow):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit(count_bow)\n",
    "    count_transform = count_vectorizer.transform(count_bow)\n",
    "    soup_count_array = count_transform.toarray()\n",
    "    soup_count_df = pd.DataFrame(soup_count_array)\n",
    "    return count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vector = count_vectorize(count_bow)\n",
    "#count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vect_compact(soup_count_df):\n",
    "    count_vect_compact = soup_count_df.loc[:,(soup_count_df.sum(axis=0) > 1)]\n",
    "    return count_vect_compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect_compact=count_vect_compact(soup_count_df)\n",
    "#count_vect_compact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By only selecting terms (columns) that are included in more than one movie, we reduce a lot of unnecessary computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup_count_df.shape)\n",
    "print(compact_count_vect.shape)\n",
    "print(compact_count_vect.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_tfidf_matrix(df):\n",
    "    tfidf_feature_list = ['movie_info']\n",
    "    tfidf_features = df[tfidf_feature_list]\n",
    "    tfidf_features.fillna(' ', inplace=True, axis=0)\n",
    "    tfidf_matrix = df[tfidf_features]\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_matrix = define_tfidf_matrix(movies)\n",
    "#tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tfidf_matrix(tfidf_matrix):\n",
    "    cleaned_tfidf_matrix = tfidf_matrix.apply(lambda x: remove_punctuation(x))\n",
    "    cleaned_tfidf_matrix = pd.Series(cleaned_tfidf_matrix)\n",
    "    cleaned_tfidf_matrix = lowercase_text(cleaned_tfidf_matrix)\n",
    "    return clean_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_tfidf_matrix = clean_tfidf_matrix(movies['movie_info'])\n",
    "#clean_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_bow(clean_tfidf_matrix):\n",
    "    tfidf_bow = pd.Series([y for x in clean_tfidf_matrix.values.flatten() for y in x.split()]).value_counts()\n",
    "    return tfidf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_bow = create_tfidf_bow(clean_tfidf_matrix)\n",
    "#tfidf_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorize(tfidf_bow):\n",
    "    tfidf_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "    tfidf_vectorizer.fit(tfidf_bow)\n",
    "    tfidf_transform = tfidf_vectorizer.transform(tfidf_bow)\n",
    "    soup_tfidf_array = tfidf_transform.toarray()\n",
    "    soup_tfidf_df = pd.DataFrame(soup_tfidf_array)\n",
    "    return soup_tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup_tfidf_df = tfidf_vectorize(tfidf_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Features for Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_features = ['genres', 'directors', 'authors', 'actors', 'production_company']\n",
    "tfidf_vec_features = ['movie_info']\n",
    "movie_titles =       ['movie_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Opens and reads CSV files\n",
    "    critic_reviews, movies = open_csv_files()\n",
    "    \n",
    "    # Prints overview of Files\n",
    "    print_orig_columns_na(critic_reviews, movies)\n",
    "    \n",
    "    # Drops duplicate values\n",
    "    movies_no_dups = drop_movie_dups(movies, movie_titles)\n",
    "    \n",
    "    # Defines features for creating word-count matrix\n",
    "    count_features = define_count_features(movies_no_dups, count_vec_features)\n",
    "    \n",
    "    # Text processing/cleaning for count matrix\n",
    "    clean_features = clean_count_features(count_features)\n",
    "    \n",
    "    # Creates a 'Bag of Words' for each movie, this combines all inlcuded terms\n",
    "    count_bow = create_count_bow(clean_features)\n",
    "    \n",
    "    # Creates the count matrix\n",
    "    count_vector = count_vectorize(count_bow)\n",
    "    \n",
    "    # \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
