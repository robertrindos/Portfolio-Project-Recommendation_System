{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, util\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_movie1='Pulp Fiction'\n",
    "favorite_movie2='Django Unchained'\n",
    "favorite_movie3='Dude Wheres my car?'\n",
    "movies_url = 'https://raw.githubusercontent.com/robertrindos/Recommendation-System/main/rotten_tomatoes_movies.csv'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_critic_reviews_csv(critic_reviews_url):\n",
    "    critic_reviews = pd.read_csv(critic_reviews_url)\n",
    "    return critic_reviews\n",
    "\n",
    "def open_movies_csv(movies_url):\n",
    "    movies = pd.read_csv(movies_url)\n",
    "    return movies\n",
    "movies = open_movies_csv(movies_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_orig_columns_na(movies, critic_reviews):\n",
    "    print(\"critic_reviews.csv NA ccount: \", critic_reviews.isna().sum())\n",
    "    print(\"critic_reviews.csv length: \", len(critic_reviews))\n",
    "    print(\" \")\n",
    "    print(\"movies.csv NA count: \", movies.isna().sum())\n",
    "    print(\"movies.csv length: \", len(movies))\n",
    "#print_orig_columns_na(movies, critic_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comma_to_space(text_df):\n",
    "    for col in text_df:\n",
    "        text_df[col].apply(lambda x: str(x).replace(',', ' '))\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text_df):\n",
    "    for col in text_df:\n",
    "        text_df[col].apply(lambda x: str(x).replace(' ', ''))\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_movie_dups(df):\n",
    "    df.drop_duplicates('movie_title').reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=drop_movie_dups(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_count_features(df, count_vec_features):\n",
    "    count_vec_features = ['genres', 'directors', 'authors', 'actors', 'production_company']\n",
    "    count_features = df[count_vec_features]\n",
    "    return count_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_features = ['genres', 'directors', 'authors', 'actors', 'production_company']\n",
    "count_features = define_count_features(movies,count_vec_features)\n",
    "#count_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_count_features(count_features):\n",
    "    clean_features = count_features.fillna(' ', inplace=False)\n",
    "    for col in clean_features:\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace(' ', ''))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace(',', ' '))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).lower())\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('[^\\w\\s]+',''))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('&', ' '))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('.', ''))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('<', ''))\n",
    "        clean_features[col] = clean_features[col].apply(lambda x: str(x).replace('>', ''))\n",
    "    return clean_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_features=clean_count_features(count_features)\n",
    "#clean_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_bow(clean_features):\n",
    "    count_vec_features = ['genres', 'directors', 'authors', 'actors', 'production_company']\n",
    "    count_bow = clean_features[count_vec_features].agg(' '.join, axis=1)\n",
    "    return count_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bow = create_count_bow(clean_features)\n",
    "#count_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(bow):\n",
    "    token_array=[]\n",
    "    for text in bow:\n",
    "        tokens=word_tokenize(text)\n",
    "        token_array.append(tokens)\n",
    "    token_df = pd.DataFrame(token_array)\n",
    "    token_df.replace(to_replace=[None], value=' ', inplace=True)\n",
    "    return token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized=tokenize(count_bow)\n",
    "#tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorize(count_bow):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit(count_bow)\n",
    "    count_transform = count_vectorizer.transform(count_bow)\n",
    "    soup_count_array = count_transform.toarray()\n",
    "    count_vector = pd.DataFrame(soup_count_array)\n",
    "    return count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = count_vectorize(count_bow)\n",
    "#count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vect_compact(count_vect):\n",
    "    compact_vector = count_vect.loc[:,(count_vect.sum(axis=0) > 1)]\n",
    "    compact_vector = pd.DataFrame(compact_vector)\n",
    "    return compact_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_vector=count_vect_compact(count_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       2       4       10      14      15      16      18      19      20      \\\n",
      "0           0       0       0       0       1       0       0       0       0   \n",
      "1           0       0       0       0       0       0       0       0       0   \n",
      "2           0       0       0       0       0       0       0       0       0   \n",
      "3           0       0       0       0       0       0       0       0       0   \n",
      "4           0       0       0       0       0       0       0       0       0   \n",
      "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "17707       0       0       0       0       0       0       0       0       0   \n",
      "17708       0       0       0       0       0       0       0       0       0   \n",
      "17709       0       0       0       0       0       0       0       0       0   \n",
      "17710       0       0       0       0       0       0       0       0       0   \n",
      "17711       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "       29      ...  223172  223173  223174  223176  223177  223179  223180  \\\n",
      "0           0  ...       0       0       0       0       0       0       0   \n",
      "1           0  ...       0       0       0       0       0       0       0   \n",
      "2           0  ...       0       0       0       0       0       0       0   \n",
      "3           0  ...       0       0       0       0       0       0       0   \n",
      "4           0  ...       0       0       0       0       0       0       0   \n",
      "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "17707       0  ...       0       0       0       0       0       0       0   \n",
      "17708       0  ...       0       0       0       0       0       0       0   \n",
      "17709       0  ...       0       0       0       0       0       0       0   \n",
      "17710       0  ...       0       0       0       0       0       0       0   \n",
      "17711       0  ...       0       0       0       0       0       0       0   \n",
      "\n",
      "       223190  223196  223199  \n",
      "0           0       0       0  \n",
      "1           0       0       0  \n",
      "2           0       0       0  \n",
      "3           0       0       0  \n",
      "4           0       0       0  \n",
      "...       ...     ...     ...  \n",
      "17707       0       0       0  \n",
      "17708       0       0       0  \n",
      "17709       0       0       0  \n",
      "17710       0       0       0  \n",
      "17711       0       0       0  \n",
      "\n",
      "[17712 rows x 70503 columns]\n"
     ]
    }
   ],
   "source": [
    "print(compact_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By only selecting terms (columns) that are included in more than one movie, we reduce a lot of unnecessary computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_recommendation(title, cosine_sim):\n",
    "    title=title.replace(' ', '',regex=True).lower()\n",
    "    index=movies_no_dups.index\n",
    "    titles=pd.Series(titles.replace(' ','',regex=True).lower())\n",
    "    indices=pd.Series(index, index=titles)\n",
    "    idx = indices[title]\n",
    "    sim_list = list(enumerate(cosine_sim[idx]))\n",
    "    sim_list = sorted(sim_list, key=lambda x: x[1], reverse=True)\n",
    "    top_10_list = sim_list[1:11]\n",
    "    movie_indices = [i[0] for i in top_10_list]\n",
    "    return titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_ddf =dd.from_pandas(compact_vector, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(vector_ddf, vector_ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_movie1='Pulp Fiction'\n",
    "recommendation_list1 = movie_recommendation(favorite_movie1, cosine_sim)\n",
    "    print(recommendation_list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Features for Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3a93239cb79c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-3a93239cb79c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcount_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mcompact_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount_vect_compact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcosine_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompact_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompact_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    favorite_movie1='Pulp Fiction'\n",
    "    favorite_movie2='Django Unchained'\n",
    "    favorite_movie3='Dude Wheres my car?'\n",
    "    movies_url = 'https://raw.githubusercontent.com/robertrindos/Recommendation-System/main/rotten_tomatoes_movies.csv'\n",
    "    #critic_reviews_url = 'poop'\n",
    "    \n",
    "    # Opens and reads CSV files\n",
    "    movies = open_movies_csv(movies_url)\n",
    "    \n",
    "    \n",
    "    # Defining features and title\n",
    "    count_vec_features = ['genres', 'directors', 'authors', 'actors', 'production_company']\n",
    "    titles = movies['movie_title']\n",
    "    \n",
    "    # Drops duplicate values\n",
    "    movies_no_dups = drop_movie_dups(movies)\n",
    "    \n",
    "    # Defines features for creating word-count matrix\n",
    "    count_features = define_count_features(movies_no_dups, count_vec_features)\n",
    "    \n",
    "    # Text processing/cleaning for count matrix\n",
    "    clean_features = clean_count_features(count_features)\n",
    "    \n",
    "    # Creates a 'Bag of Words' for each movie, this combines all inlcuded terms\n",
    "    count_bow = create_count_bow(clean_features)\n",
    "    \n",
    "    # Creates the count matrix\n",
    "    count_vector = count_vectorize(count_bow)\n",
    "    \n",
    "    compact_vector=count_vect_compact(count_vector)\n",
    "    \n",
    "    cosine_sim = cosine_similarity(compact_vector, compact_vector)\n",
    "    \n",
    "    recommendation_list1 = movie_recommendation(favorite_movie1, cosine_sim)\n",
    "    print(recommendation_list1)\n",
    "    \n",
    "    recommendation_list2 = movie_recommendation(favorite_movie2, cosine_sim)\n",
    "    print(recommendation_list2)\n",
    "    \n",
    "    recommendation_list3 = movie_recommendation(favorite_movie3, cosine_sim)\n",
    "    print(recommendation_list3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
